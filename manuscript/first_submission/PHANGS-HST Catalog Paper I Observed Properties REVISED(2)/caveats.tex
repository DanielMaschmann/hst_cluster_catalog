
%\subsection{Notes for Catalog Users}\label{ssect:caveats}


%Before taking the step from the observation catalogs presented here to the physical interpretation of the cluster ensembles, one must first clarify how complete the respective catalogs are. Furthermore, the catalog user needs to be conscious about the main differences between the human and the ML catalogs.

% distance
%As described above, the galaxy distance is one of the most obvious limitations, which causes a shift of the faintest detected clusters as we can see in Figure~\ref{fig:v_mag_panel}. 
% difference between ML and HUMAN
This figure also reveals the difference in magnitude between the human and the ML catalogs which is the direct consequence of the human classification being focused on the brightest clusters. 
The user of the catalog should therefore always consider the magnitude limits for each individual galaxy when using the human catalogs. 
On the other hand when the main interest of an analysis is the population of the bright end we recommend using the human catalogs as some of the brightest clusters were not recovered by the ML algorithm.
% % the trade off between deep or better classified samples
% The human catalogs are by construction better classified than the ML catalogs as they are the basis of the ML classification. However, the latter go significantly deeper in magnitude and provides a larger statistical power. 
As shown in Figure~\ref{fig:v_abs_mag}, the luminosity function of the human and ML samples have different turnover points of $M_{\rm V} \sim -7.9$ and $-7.1$, respectively. 
However, as pointed out in the previous section the ML catalogs are missing some of the brightest clusters. Nevertheless, no strong dependency of the ML classification was found for clusters brighter than $M_{\rm V} > -7.8$ \citep{whitmore_star_2021}. This means that when taking the ML recovery rate into account, one can view the ML sample as complete till its turnover point.
The discussion in \citet{whitmore_using_2011} can help the catalog user to understand how the choice of the human or ML classified samples affects the results. We, furthermore, highly encourage the user to explore both catalog types and discuss how their main results are influenced by the cluster classification.

%An additional aspect of the ML catalogs, the user needs to be aware of, is the impact of falsely classified cluster candidates. 
%The classification accuracy is quantitatively described with a classification confusion matrix in Figure~2 of \citet{hannon_star_2023}. 
%In fact, about $15\,\%$ and $2\,\%$ of genuine class 1 clusters are miss-classified as class 2 and class 3 objects, respectively. 
%The ML classification of true class 2 clusters results in a false classification of class 2 and class 3 objects in $12\,\%$ and $18\,\%$ of the cases. 

ML classification accuracy in our catalogs is quantitatively described with a classification confusion matrix in Figure~2 of \citet{hannon_star_2023}. They demonstrate overall high accuracy of $74\,\%$ and $59\,\%$ for class 1 and class 2 clusters. These numbers reassure the use of combined Class 1 and 2 samples, which typically form the basis of star cluster studies. 

%Class 3 compact associations, however show the largest contamination: $23\,\%$ of class 4 objects, which are no star clusters, are miss-classified as class 3 objects. As we know from Table~\ref{tab:numbers}, 16555 objects of 38343 inspected objects ($43\,\%$) are class 4 objects (See Section~\ref{ssect:cat_content} for a definition). 
%As a consequence, we can extrapolate this fraction on the $\sim 190,000$ candidates and expect $\sim 80,000$ class 4 objects of which statistically $\sim 18,000$ are falsely classified as class 3 compact association. 
Even though this suggests that $\sim 1/3$ of class 3 objects are no star clusters (class 4), it needs to be said that the distinction between C3 and the smallest substructures within multi-scale stellar associations is fluid with a large degree of overlap \citep{larson_multi-scale_2022}. 

A large fraction of class 4 objects are doublets and triplets ($46\,\%$) of bright stars which is most likely the origin of the high percentage of this mis-classification. 
In order to test this hypothesis, we check the percentage of class 3 compact associations which are situation inside 16, 32 and 64~pc stellar association structures provided by \citet{larson_multi-scale_2022}. 
For the 16~pc scales, we find an agreement of 57\,\% and 47\,\% between class 3 compact associations for the human and ML classification, respectively. For the 32~pc scale these numbers are 80\,\% and 69\,\% and for the 64~pc 83\,\% and 74\,\%. The almost constant difference of $\sim10\,\%$ between the human and ML sample suggests, that the true contamination of non cluster objects in the ML classified class 3 compact association is in fact around $10\,\%$.
%
%8pc hum  971  of  4302  cl3 are in stellar ass. (22.6) 
%8pc ml  7281  of  47041  cl3 are in stellar ass. (15.5) 
%16pc hum  3568  of  6240  cl3 are in stellar ass. (57.2) 
%16pc ml  29791  of  63206  cl3 are in stellar ass. (47.1) 
%32pc hum  4977  of  6240  cl3 are in stellar ass. (79.8) 
%32pc ml  43655  of  63206  cl3 are in stellar ass. (69.1) 
%64pc hum  5230  of  6240  cl3 are in stellar ass. (83.8) 
%64pc ml  46657  of  63206  cl3 are in stellar ass. (73.8) 


% incompletenes due to background
An additional source of local incompleteness of the catalogs are bright backgrounds. In the central regions of NGC\,1566, 3627, 1317 and 4548, we do not detect any star clusters (See Figure~\ref{fig:spatial_dist}, and \ref{fig:spatial_dist_1}-\ref{fig:spatial_dist_9} for a visualization of the spatial cluster distribution). In fact, the background in these regions is so bright that it is not possible to detect any candidates in the first place. This also leads to different detection limits for star clusters depending on the environment. 
We, therefore, urge the user to also include the spatial distribution when performing an analysis which is sensitive to detection limits.
This caveat can be quantified with the magnitude and spatial location dependent recovery fraction of artificial clusters similar to \citet{adamo_legacy_2017}. This however, would exceed the scope of the present paper and is a project on its own addressed in the future. 

% usage of all clusters
In case the catalog user aims to obtain a complete cluster sample from all 38 galaxies, a common cut needs to be found. This can be achieved by either using the brightest turnover point amongst all galaxies in the luminosity (in practice, $M_V$) function, or by establishing age and stellar mass limits satisfied by the catalogs for all targets. For the latter choice, this option is enabled by the stellar mass and age estimations from Paper~II, in which suggested limits are provided.
%In practice, we would consider the sub sample of $\log(M_{*}) > 4.3 M_{\odot}$ and ages of $< 100$\,Myr (For a better estimation, see Paper~II). It needs to be said, that such a choice would lead to a significantly smaller sample and would only allow the study of the most massive and relatively young star clusters.



SECTION 3.3 - MOTIVATIONS, CAVEATS, AND COMPARISON STRATEGIES
 
"An approach employing both human and machine learning classifications was choosen for three basic reasons. 1. The large number of candidate clusters makes it prohibitive to classify them all manually, 2. ) human classificaiton is not objective, 3) a training set is needed to "teach" the machine learning. In principle, it might be hoped that the agreement between human and ML classification would be so robust that the we can rely entirely on the ML catalog once it is built. While the current state of the art is quite promising (especially for C1+C2), we are not yet at a stage where  ML classification can be used blindly - care  must be taken.
If all galaxies in our sample were at the same distance, had similar levels of crowding, the same levels of background, the same morphologies, the same levels of foreground and background contamination, ... -  training a machine learning classificaiton program would be a much easier business. For all these reasons  and more, caution is necessary when using the current generation of machine learning classificaitons. Machine learning classifications will continue to improve (e.g., see future plans in Whitmore et al, 2021 and Hannon 2023), but the subject is still in its infancy.
With this in mind, here are some potential comparison strategies to consider.
- Compare results obtained using both human and machine learning catalog.
- Compare results using different magnitude limits. While the normal tendency is to maximize the size of your sample, this is where systmatic selection effects are likely to appear. In most cases the clear signal is in the bright part of the distribution, and you will end up chasing noise at the fainter levels. For example, based on Figure 3 a magnirude cutoff of Mv = -8 mag is a natural breaking point that will minimize differences between human and ML catalogs.
- Compare samples at difference distances.
- Compare difference parts of galaxies (e.g., exclude the inner very crowded, high background parts of the galaxy).
- Compare using C1 vs C2 vs C1+C2, as suggested in Whitmore et al. 2021, Thilker 2024, and demonstrated in several figures in the current paper (eg., figures 5, 6, 8)
If your primary results provide a much stronger signal than the scatter in these different comparisons, you can be sure you have a robust result.
 Cluster classifcation is still a rather messy business, but it works well enough to produce several striking results. An example is the dramatic difference in the distributions of C1, C2, and C3, and the strong similarity of the results for the human and ML catalogs when the same V-band cut is made (i.e., the top vs.  bottom plots in Figure 6).
See Wei et al. 2020, Whitmore et al. 2021, Perez et al. 2021, and Hannon et al. 2023 for related suggestions, more detailed advice, and other examples of how well the ML classifications are performing for specific science topics."


