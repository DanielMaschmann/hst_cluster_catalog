Dear Adam,  Really, really good comments.  Thank you for making the time in your busy schedule to read, think, and write up your thoughts for us.  -Janice
 
From: "Leroy, Adam" <leroy.42@osu.edu>
Date: Sunday, September 17, 2023 at 11:57 AM
To: "danielmaschmann@arizona.edu" <danielmaschmann@arizona.edu>
Cc: Janice Lee <jlee@stsci.edu>, Dave Thilker <dthilker@pha.jhu.edu>
Subject: Cluster paper feedback
 
External Email - Use Caution
Hi Daniel,
 
(feel free to ignore or to forward as useful)
 
Super impressive work putting together what's sure to be a very impactful legacy data product. It's late in the game and I'm sure you're getting a ton of sentence by sentence markup and citation suggestions, so I wanted to flag mainly two high level things and then offer to give sentence by sentence markup if you feel you need it anywhere:
Reading it as a likely catalog user, I do get a clear idea from the text that distance and environment matter for completeness and that simulations (or maybe some very fancy version of false cluster tests) would be needed to get a real completeness function but aren't present yet. But I don't get a clear idea of quite what you would tell me to do?

Say to take a real case, I wanted to grab the Class 1+2 ML catalogs and then run the two point correlation with one of our other tracers - which is totally something we have been eagerly waiting for. What recommendation would you make to make a comparison in the results fair among galaxies? Among environments?

This is a whole giant future work package for sure, but there's a chance in the conclusions and discussion to give some advice along the lines of: "you can REALLY trust X, but be afraid of Y" that I struggled to get. The concerns seem clear, but the "how to use this awesome data set in a way that is ambitious but respects the shortcomings" could maybe use some sharpening.

It's a tricky thing, right? Because you want to say "just be careful" but you are also releasing these into the wild, and the clearer you are with people the more likely that they use them correctly. In that sense, a "best practices" wrap up section, even a short one, would be a really good addition to the conclusions or the discussion.

 

More concrete - for part 5 it seems like the CO comparison is still mostly TBD (or just the pictures?). I'd make a pitch which I hope would be easy and still quite impactful: just measure the percentage of clusters in each subsample that overlap detected CO. The easiest way to think about PHANGS-ALMA is that every pixel where we detect CO is likely overlapping a reasonable mass molecular cloud. With the resolution of 100 pc and no super-clear evidence that the object finding algorithms pick out anything particularly special, just using the maps is physically fine and very easy.

There could easily be a short table which is just "cluster classification" and "percentage  overlapping detected CO" - happy to discuss what "detected CO" should mean for a rigorous setup, but truthfully starting by just using the "signal masked" moment 0s at a fixed physical resolution and then imposing a modest common intensity threshold in the CO then just doing the basic numbers would be cool and quite easy and a pretty rigorous comparative analysis.

I can't tell if 5 is waiting for more analysis, it read that way, which is why I'm suggesting this as a way to wrap that up -it's nice because it's easy and also anything else is sort of adding complexity for no real physical gain.

If this is something you're interested in adding, I'm super happy to iterate on Slack or chat briefly about how to do it in practice.
Planning to read through again tomorrow, again nice work.
 
Best,
Adam
 
---
 
Adam Leroy
Professor
Department of Astronomy
Ohio State University
4037 McPherson Chemical Laboratory
email: leroy.42@osu.edu
pronouns: he, him, his
 