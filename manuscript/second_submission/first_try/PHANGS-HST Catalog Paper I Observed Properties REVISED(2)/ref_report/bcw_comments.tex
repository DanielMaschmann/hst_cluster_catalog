

From: Brad Whitmore <whitmore@stsci.edu>
Date: Friday, January 19, 2024 at 9:18 AM
To: Janice Lee <jlee@stsci.edu>
Cc: "Maschmann, Daniel - (danielmaschmann)" <danielmaschmann@arizona.edu>, Brad Whitmore <whitmore@stsci.edu>
Subject: Re: BCW classifications

Hi – Here are some words from Whitmore 2021 and comments related to referees points 1 and 3, as requested. 

3.1 > “Previous works have used different numbers of people to perform
the human classifications, from a single person up to large numbers
from a citizen science approach (e.g. the PHAT survey; Johnson et al.
2015). Sampling statistics suggest that a larger number of classifiers
should result in more robust results, but this assumes that each human
classifier uses similar definitions and internal weighting systems. In
practice, most studies to date have used either a single person (e.g.
Chandar et al. 2010b; Bastian et al. 2014; Silva-Villa et al. 2014, ...),
a few people, or as many as eight people (Johnson et al. 2012). For
LEGUS, three different people from a pool of roughly a dozen classi-
fied each object for most of the galaxies, as described in Adamo et al.
(2017) (see also P´erez et al. 2021, and H. Kim et al., in preparation),
while 10 galaxies were classified by just one person, BCW.”

The key points is whether larger numbers of people improve or make things worse depends on how similar they are, which was never evaluated (or published) for LEGUS. At one point I actually did look at this and there were 2 or 3 complete outleyers of the ~ 12 classifiers that were essentially random. 

4.1 – “In general, there is no one study that appears to be much better
than the others. For example, when considering the mean values
from column 5 of Table 1 (excluding the RESNET versus VGG
comparison), three different classifier combinations have the highest
values for a given galaxy (i.e. PHANGS-HST versus VGG for NGC
628 and NGC 1566; PHANGS-HST versus RESNET for NGC 1433;
and LEGUS versus RESNET for NGC 3351).
To summarize, we find that comparisons between all four clas-
sification methods give fairly similar results; all of them appear to
provide source classifications of comparable quality.”

See Figure 18 – and section 5.5

6.3.3 – “Various sanity checks performed in
this section suggest typical completeness numbers in the 70 per cent
to 80 per cent range when considering Class 1 + 2 clusters over the
full ensemble of environments.”

Note that there are 3 subsections in 6.3 on “Issues related to completeness and systematic differences in
Classification”, including “6.3.3 Systematic differences between PHANGS–HST and LEGUS”, so  we could mention one or two of the main items and point people to this section ?

There are other items in Stephans paper that might be relevant if you think you need more. 

The referee says – “The reader should be explicitly warned that substantial uncertainties are a generic feature in the current samples of class 2-4 clusters.” – and I agree completely. We should probably paraphrase this comment and include it.

-------------------
The referee also says  in relation to the sentence (P6 – L230) >>> “Overall, the performance227
of our neural network models is comparable to the consistency between human classifiers (Wei et al. 2020; Whitmore228
et al. 2021), as well as the STARCNET models of P´erez et al. (2021), developed for classification of star clusters in the229
LEGUS survey (Calzetti et al. 2015; Linden et al. 2022); i.e., 78, 55 and 45 %. “ 

“However, this comparison could be misinterpreted to imply a much higher level of reliability in the PHANGS cluster survey, which has not been established. “

I agree with the referees comment here also – It is not fair to use something trained on PHANGS, and then evaluated on LEGUS – to compare. I tried to get Stephen to emphasize that since there are some criteria are different in some cases (e.g., class 3), all we can say is that the comparisons are different, not that ours are better.

I think we should probably just take the sentence out. 

On item 3 from referee – 

I also agree with the referee here. I advocated including class 1 by itself in several places in Whitmore 2021 (e.g., the fits in Table 4 – figure 25, etc.), but people tend to just use C1 + C2 alone in most cases to keep things from getting to long. I think including at least one example of C1 alone would be a good idea, especially since we are emphasizing the difference between class 1 and 2 in this paper quite strongly.

Cheers,
Brad





